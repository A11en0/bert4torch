{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### 准备二阶段训练数据集"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from config import *\n",
    "\n",
    "# get list\n",
    "print('读取训练用的数据集: ', fst_train_file)\n",
    "std_data=pd.read_csv(fst_train_file, sep=\"\\t\")\n",
    "q_std_list=std_data.q_std.unique().tolist()  # 标准问list\n",
    "q_sim_list=std_data.q_sim.unique().tolist()  # 相似问list\n",
    "q_corpus=pd.DataFrame(q_std_list+q_sim_list,columns=['q']).drop_duplicates(\"q\").q.tolist()\n",
    "q_std_df=pd.DataFrame(q_std_list,columns=['q'])\n",
    "q_corpus_df=pd.DataFrame(q_corpus,columns=['q'])\n",
    "q_sim_df=pd.DataFrame(q_sim_list,columns=['q'])\n",
    "\n",
    "q_std_df.to_csv(fst_q_std_file, index=None,header=False,sep=\"\\t\")\n",
    "q_corpus_df.to_csv(fst_q_corpus_file, index=None,header=False,sep=\"\\t\")\n",
    "q_sim_df.to_csv(fst_q_sim_file, index=None,header=False,sep=\"\\t\")\n",
    "print('q_std_list:——>',len(q_std_list),'q_sim_list:——>',len(q_sim_list),'q_corpus:——>',len(q_corpus))\n",
    "\n",
    "# get model\n",
    "from task_sentence_embedding_FinanceFAQ_step1_1 import model\n",
    "\n",
    "# get embeddings\n",
    "q_std_sentence_embeddings = model.encode(q_std_list,batch_size=64)\n",
    "np.save(fst_q_std_vectors_file, q_std_sentence_embeddings)\n",
    "q_corpus_sentence_embeddings = model.encode(q_corpus,batch_size=64)\n",
    "np.save(fst_q_corpus_vectors_file, q_corpus_sentence_embeddings)\n",
    "print('fst_q_std_vectors_file', fst_q_std_vectors_file)\n",
    "print('q_corpus_vectors_file', fst_q_corpus_vectors_file)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 获得第二阶段模型所需训练集"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from config import *\n",
    "from utils import *\n",
    "\n",
    "# 加载标问和标问向量\n",
    "print('加载标问和标问向量', fst_q_std_file)\n",
    "q_std_list=pd.read_csv(fst_q_std_file, sep=\"\\t\",names=['q']).q.tolist()\n",
    "q_std_sentence_embeddings=np.load(fst_q_std_vectors_file)\n",
    "print(q_std_sentence_embeddings.shape,len(q_std_list))\n",
    "\n",
    "print('加载所有语料及其向量', fst_q_corpus_file)\n",
    "q_all=pd.read_csv(fst_q_corpus_file, sep=\"\\t\",names=['q']).q.tolist()\n",
    "q_all_sentence_embeddings=np.load(fst_q_corpus_vectors_file)\n",
    "q_all_sentence_embeddings_dict={q_all[i]:q_all_sentence_embeddings[i] for i in range(0,len(q_all))}\n",
    "print(q_all_sentence_embeddings.shape,len(q_all))\n",
    "\n",
    "# # 记得选择是v1还是v2\n",
    "# # v1\n",
    "q_corpus=q_std_list\n",
    "corpus_sentence_embeddings=q_std_sentence_embeddings\n",
    "dict_2={v:v for v in q_std_list}\n",
    "pred2std_dict=dict_2\n",
    "\n",
    "print('加载标问-相似问数据集', fst_train_file)\n",
    "df_k=pd.read_csv(fst_train_file, sep=\"\\t\")\n",
    "print(\"std_data:\", df_k.shape)\n",
    "df_k=df_k[df_k.q_std.isin(q_corpus)]\n",
    "print(\"df_k:\", df_k.shape)\n",
    "\n",
    "print('从embedding中找到相似问对应的向量(去重复)'.center(60, '-'))\n",
    "texts=df_k.q_sim.tolist()\n",
    "texts_in=[v for v in texts if v in q_all_sentence_embeddings_dict.keys()]\n",
    "texts_out=[v for v in texts if v not in q_all_sentence_embeddings_dict.keys()]  # 不在所有语料中的话术\n",
    "texts_out_embeddings=model.encode(texts_out,batch_size=64)\n",
    "texts_embeddings_dict_1={texts_in[i]:q_all_sentence_embeddings_dict[texts_in[i]] for i in range(0,len(texts_in))}\n",
    "texts_embeddings_dict_2={texts_out[i]:texts_out_embeddings[i]  for i in range(0,len(texts_out))}\n",
    "texts_embeddings_dict={**texts_embeddings_dict_1, **texts_embeddings_dict_2}\n",
    "print(len(texts_embeddings_dict))\n",
    "\n",
    "print('计算相似度'.center(60, '-'))\n",
    "\n",
    "K = 20\n",
    "x_texts=texts\n",
    "x_texts_embeddings=np.array([texts_embeddings_dict[x_text] for x_text in x_texts])\n",
    "cos_scores = pytorch_cos_sim(x_texts_embeddings,corpus_sentence_embeddings).cpu()\n",
    "print(x_texts_embeddings.shape, corpus_sentence_embeddings.shape, cos_scores.shape)\n",
    "\n",
    "print(f'为每条相似问找到相似度最大的{K}条标问'.center(60, '-'))\n",
    "cos_scores_top_k_values, cos_scores_top_k_idx = torch.topk(cos_scores, K, dim=1, largest=True, sorted=False)\n",
    "cos_scores_top_k_values = cos_scores_top_k_values.tolist()\n",
    "cos_scores_top_k_idx = cos_scores_top_k_idx.tolist()\n",
    "cos_q_corpus_sort=[[q_corpus[v] for v in vlist] for vlist in cos_scores_top_k_idx ]\n",
    "result=[list(zip(cos_q_corpus_sort[i],cos_scores_top_k_values[i])) for i in range(0,len(x_texts))]\n",
    "texts_topk_dict={texts[i]:result[i] for i in range(0,len(texts))}\n",
    "\n",
    "texts_topk_dict['查询近期全市场将上市的新股']\n",
    "\n",
    "# 拿到每个相似问的预测结果，topK的预测标问和对应的相似度\n",
    "df_k['q_std_pred_list']=df_k.q_sim.map(texts_topk_dict)\n",
    "# 计算q_sim和q_std之间的相似度\n",
    "df_k['prob_with_std']=df_k.apply(lambda row:cos_sim_1(texts_embeddings_dict[row['q_sim']],\n",
    "                                                      corpus_sentence_embeddings[q_corpus.index(row['q_std'])]),axis=1)\n",
    "\n",
    "# df_k['q_std_pred_list']=df_k.q_std_pred_list.apply(lambda v:eval(v))\n",
    "df_k['q_std_pred_list_v1']=df_k.q_std_pred_list.apply(lambda v:[k[0] for k in v])  # 只保留预测的标准问句\n",
    "df_k['q_std_pred_list_v2']=df_k.q_std_pred_list.apply(lambda v:[k[1] for k in v])  # 只保留预测的概率\n",
    "df_k['t1']=df_k.apply(lambda row:1 if row['q_std'] in row['q_std_pred_list_v1'][0:1] else 0,axis=1)\n",
    "df_k['t3']=df_k.apply(lambda row:1 if row['q_std'] in row['q_std_pred_list_v1'][0:3] else 0,axis=1)\n",
    "df_k['t5']=df_k.apply(lambda row:1 if row['q_std'] in row['q_std_pred_list_v1'][0:5] else 0,axis=1)\n",
    "df_k['t10']=df_k.apply(lambda row:1 if row['q_std'] in row['q_std_pred_list_v1'][0:10] else 0,axis=1)\n",
    "\n",
    "df_k.to_csv(fst_std_data_results, index=None, sep=\"\\t\")\n",
    "\n",
    "print('模型第一阶段(含训练和测试)准确率如下：——>')\n",
    "print(df_k.shape)\n",
    "print(df_k.t1.sum()/df_k.shape[0],df_k.t3.sum()/df_k.shape[0],df_k.t5.sum()/df_k.shape[0],df_k.t10.sum()/df_k.shape[0])\n",
    "df_k.head()\n",
    "\n",
    "xdf=df_k.copy(deep=True)\n",
    "# xdf['q_std_pred_list']=xdf.q_std_pred_list.apply(lambda v:eval(v))\n",
    "print('预测结果中和q_std不一致的'.center(60, '-'))\n",
    "xdf['q_std_pred_list_else']=xdf.apply(lambda row:[v for v in row['q_std_pred_list'] if v[0]!=row['q_std']],axis=1 )\n",
    "xdf['q_std_pred_list_else_v1']=xdf.q_std_pred_list_else.apply(lambda v:[m[0] for m in v])\n",
    "xdf['q_std_pred_list_else_v2']=xdf.q_std_pred_list_else.apply(lambda v:[m[1] for m in v])\n",
    "\n",
    "##used\n",
    "# xdf['pairs']=xdf.apply(lambda row: ['1'+'\\t'+row['q_sim']+'\\t'+row['q_std']+'\\t'+'1']+['0'+'\\t'+row['q_sim']+'\\t'+v[0]+'\\t'+str(v[1]) for v in row['q_std_pred_list_else'][1:11]],axis=1)\n",
    "##暂时\n",
    "\n",
    "print('组织正负样本'.center(60, '-'))\n",
    "xdf['pairs']=xdf.apply(lambda row: ['1'+'\\t'+row['q_sim']+'\\t'+row['q_std']+'\\t'+'1']+['0'+'\\t'+row['q_sim']+'\\t'+v[0]+'\\t'+str(v[1]) for v in row['q_std_pred_list_else'][0:10]],axis=1)\n",
    "print(xdf.iloc[0]['pairs'])\n",
    "\n",
    "print('单独处理正负样本'.center(60, '-'))\n",
    "q_sim_list=xdf.drop_duplicates(\"q_sim\").q_sim.tolist()\n",
    "q_std_list=xdf.drop_duplicates(\"q_std\").q_std.tolist()\n",
    "q_sim_dict={q_sim_list[i]:i for i in range(0,len(q_sim_list))}\n",
    "q_std_dict={q_std_list[i]:i for i in range(0,len(q_std_list))}\n",
    "pairs=xdf.pairs.tolist()\n",
    "pairs_list=[v.split('\\t') for vlist in pairs for v in vlist]\n",
    "pairs_df=pd.DataFrame(pairs_list,columns=['label','q_sim','q_std','prob'])\n",
    "print(pairs_df.drop_duplicates(['q_std','q_sim']).shape)\n",
    "pairs_df.head()\n",
    "\n",
    "pairs_df_2=pairs_df.sort_values('label',ascending=0).drop_duplicates(['q_sim','q_std'])\n",
    "pairs_df_final=pairs_df_2\n",
    "print(pairs_df_final.shape,pairs_df.shape)\n",
    "\n",
    "print('对于每一个q_sim，仅保留概率最高的10条样本')\n",
    "pairs_df_final['prob']=pairs_df_final.prob.astype(\"float\")\n",
    "pairs_df_final['nrank']=pairs_df_final.groupby(['label','q_sim'])['prob'].rank(ascending=0,method='first')\n",
    "df_final=pairs_df_final[pairs_df_final.nrank<=9].reset_index(drop=True)\n",
    "df_final['sim_idx']=df_final.q_sim.map(q_sim_dict)\n",
    "df_final['std_idx']=df_final.q_std.map(q_std_dict)\n",
    "df_final=df_final.sort_values(['sim_idx','label','nrank'],ascending=[1,0,1])[['label','q_sim','q_std']].reset_index(drop=True)\n",
    "\n",
    "print('对于每一条标问，随机挑选一条样本作为dev集合')\n",
    "xdf['dev_rnd']=xdf.q_std.apply(lambda v:np.random.rand())\n",
    "xdf['nrank_dev']=xdf.groupby('q_std')['dev_rnd'].rank(ascending=0,method='first')\n",
    "q_sim_choose_dev=xdf[xdf.nrank_dev<=1].drop_duplicates(['q_sim']).q_sim.tolist()\n",
    "df_train=df_final.copy(deep=True)\n",
    "print('df_train shape:',df_train.shape)\n",
    "df_dev=df_final[df_final.q_sim.isin(q_sim_choose_dev)]\n",
    "print('df_dev shape',df_dev.shape)\n",
    "print('第二阶段train集: ', sec_train_file)\n",
    "df_train[['label','q_std','q_sim']].to_csv(sec_train_file, sep=\"\\t\",index=None,header=False)\n",
    "print('第二阶段dev集: ', sec_dev_file)\n",
    "df_dev[['label','q_std','q_sim']].to_csv(sec_test_file, sep=\"\\t\",index=None,header=False)\n",
    "df_dev[['label','q_std','q_sim']].to_csv(sec_dev_file, sep=\"\\t\",index=None,header=False)\n",
    "df_train.head()"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}