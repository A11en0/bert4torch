{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## 计算向量，统计结果等\n",
    "### 获得基于第二阶段模型所得标问向量"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from task_sentence_embedding_FinanceFAQ_step2_1 import model\n",
    "from config import *\n",
    "\n",
    "# get list\n",
    "q_std_list = pd.read_csv(q_std_file, sep=\"\\t\", names=['c']).c.tolist()\n",
    "q_corpus = pd.read_csv(q_corpus_file, sep=\"\\t\", names=['c']).c.tolist()\n",
    "\n",
    "# get embeddings\n",
    "q_std_sentence_embeddings = model.encode(q_std_list, batch_size=64)\n",
    "print('保存二阶段标准问向量：', sec_q_std_vectors_file)\n",
    "np.save(sec_q_std_vectors_file, q_std_sentence_embeddings)\n",
    "q_corpus_sentence_embeddings = model.encode(q_corpus, batch_size=64)\n",
    "print('保存二阶段所有语料向量：', sec_q_corpus_vectors_file)\n",
    "np.save(sec_q_corpus_vectors_file, q_corpus_sentence_embeddings)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 获得所有待测数据第一阶段模型预测结果"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from config import *\n",
    "from utils import *\n",
    "from task_sentence_embedding_FinanceFAQ_step1_1 import model\n",
    "\n",
    "path_list = fst_eval_path_list\n",
    "\n",
    "# 加载模型\n",
    "print('读取标准问及其向量'.center(60, '-'))\n",
    "q_std_list = pd.read_csv(q_std_file, sep=\"\\t\", names=['c']).c.tolist()\n",
    "q_std_sentence_embeddings = np.load(fst_q_std_vectors_file)\n",
    "print('标准问shape：', q_std_sentence_embeddings.shape, len(q_std_list))\n",
    "\n",
    "print('读取所有语料及其向量'.center(60, '-'))\n",
    "q_all = pd.read_csv(q_corpus_file, sep=\"\\t\", names=['c']).c.tolist()\n",
    "q_all_sentence_embeddings = np.load(fst_q_corpus_vectors_file)\n",
    "q_all_sentence_embeddings_dict = {q_all[i]: q_all_sentence_embeddings[i] for i in range(0, len(q_all))}\n",
    "print('所有问句数量：——>', q_all_sentence_embeddings.shape, len(q_all))\n",
    "\n",
    "for i in range(0, len(path_list)):\n",
    "    print(f'开始评估新语料: {i}'.center(120, '='))\n",
    "    df_eval = pd.read_csv(path_list[i][0], sep=\"\\t\")\n",
    "    df_eval = df_eval[~pd.isna(df_eval.q_sim)]\n",
    "    outputpath = path_list[i][1]\n",
    "    print('input_path: ', path_list[i][0], 'output_path: ', outputpath)\n",
    "\n",
    "    df_eval['ifin'] = df_eval.q_std.apply(lambda v: 1 if v in q_std_list else 0)\n",
    "    print(\"目标语料标问是否存在：——>\", df_eval.groupby(\"ifin\")[\"ifin\"].count())\n",
    "    print(\"目标语料数量：\", df_eval.shape, '标问数量：', df_eval.drop_duplicates(\"q_std\").shape[0], '相似问数量：',\n",
    "          df_eval.drop_duplicates(\"q_sim\").shape[0], '标语料去重后数量', df_eval.drop_duplicates([\"q_std\", \"q_sim\"]).shape[0])\n",
    "    texts = df_eval.q_sim.tolist()\n",
    "    texts_in = [v for v in texts if v in q_all_sentence_embeddings_dict.keys()]\n",
    "    texts_out = [v for v in texts if v not in q_all_sentence_embeddings_dict.keys()]\n",
    "    texts_out_embeddings = model.encode(texts_out, batch_size=64)\n",
    "    texts_embeddings_dict_1 = {texts_in[i]: q_all_sentence_embeddings_dict[texts_in[i]] for i in range(0, len(texts_in))}\n",
    "    texts_embeddings_dict_2 = {texts_out[i]: texts_out_embeddings[i] for i in range(0, len(texts_out))}\n",
    "    texts_embeddings_dict = {**texts_embeddings_dict_1, **texts_embeddings_dict_2}\n",
    "    print('目标语料编码后数量：——>', len(texts_embeddings_dict))\n",
    "\n",
    "    ## v1 对于都是有一个是小量的情况下\n",
    "    df_eval = cal_performance(texts_embeddings_dict, q_std_sentence_embeddings, q_std_list, texts, df_eval, K=10)\n",
    "    df_eval.to_csv(outputpath, index=None, sep=\"\\t\")\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 获得所有待测数据第二阶段模型预测结果"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import os\n",
    "import torch\n",
    "from task_sentence_embedding_FinanceFAQ_step2_1 import model\n",
    "import numpy as np\n",
    "import logging\n",
    "import pandas as pd\n",
    "from config import *\n",
    "\n",
    "path_list = sec_eval_path_list\n",
    "\n",
    "q_std_list = pd.read_csv(os.path.join(data_dir, q_std_file), sep=\"\\t\", names=['c']).c.tolist()\n",
    "q_std_sentence_embeddings = np.load(os.path.join(data_dir, sec_q_std_vectors_file))\n",
    "print('标问数量：——>', q_std_sentence_embeddings.shape, len(q_std_list))\n",
    "q_all = pd.read_csv(os.path.join(data_dir, q_corpus_file), sep=\"\\t\", names=['c']).c.tolist()\n",
    "q_all_sentence_embeddings = np.load(os.path.join(data_dir, sec_q_corpus_vectors_file))\n",
    "q_all_sentence_embeddings_dict = {q_all[i]: q_all_sentence_embeddings[i] for i in range(0, len(q_all))}\n",
    "print('所有问句数量：——>', q_all_sentence_embeddings.shape, len(q_all))\n",
    "\n",
    "q_corpus = q_std_list\n",
    "corpus_sentence_embeddings = q_std_sentence_embeddings\n",
    "corpus_sentence_embeddings_dict = {q_corpus[i]: corpus_sentence_embeddings[i] for i in range(0, len(q_corpus))}\n",
    "dict_2 = {v: v for v in q_std_list}\n",
    "pred2std_dict = dict_2\n",
    "\n",
    "for i in range(0, len(path_list)):\n",
    "    print(f'开始评估新语料: {i}'.center(120, '='))\n",
    "    # # # ##v1\n",
    "    df_k = pd.read_csv(path_list[i][0], sep=\"\\t\")\n",
    "    outputpath = path_list[i][1]\n",
    "    print(path_list[i][0])\n",
    "    print(outputpath)\n",
    "\n",
    "    texts = df_k.q_sim.tolist()\n",
    "    texts_in = [v for v in texts if v in q_all_sentence_embeddings_dict.keys()]\n",
    "    texts_out = [v for v in texts if v not in q_all_sentence_embeddings_dict.keys()]\n",
    "    texts_out_embeddings = model.encode(texts_out, batch_size=64)\n",
    "    texts_embeddings_dict_1 = {texts_in[i]: q_all_sentence_embeddings_dict[texts_in[i]] for i in\n",
    "                               range(0, len(texts_in))}\n",
    "    texts_embeddings_dict_2 = {texts_out[i]: texts_out_embeddings[i] for i in range(0, len(texts_out))}\n",
    "    texts_embeddings_dict = {**texts_embeddings_dict_1, **texts_embeddings_dict_2}\n",
    "    print('目标语料编码数量：——>', len(texts_embeddings_dict))\n",
    "\n",
    "\n",
    "    def cos_sim4matrix_2(arr, brr):\n",
    "        return (arr.dot(brr.T) / (np.sqrt(np.sum(arr * arr)) * np.sqrt(np.sum(brr * brr, axis=1))))\n",
    "\n",
    "\n",
    "    def get_sec_result(text, std_texts):\n",
    "        a_text_embeddings = texts_embeddings_dict[text]\n",
    "        b_text_embeddings = np.array([corpus_sentence_embeddings_dict[v] for v in std_texts])\n",
    "        #     print(a_text_embeddings.shape,b_text_embeddings.shape)\n",
    "        sims_with_std = cos_sim4matrix_2(a_text_embeddings, b_text_embeddings).reshape(-1)\n",
    "        sort_idx = np.argsort(-sims_with_std).tolist()\n",
    "        intents_sort = [std_texts[idx] for idx in sort_idx]\n",
    "        sims_values = [sims_with_std[idx] for idx in sort_idx]\n",
    "        result = list(zip(intents_sort, sims_values))\n",
    "        return (result)\n",
    "\n",
    "\n",
    "    # get_sec_result(text,std_texts)\n",
    "\n",
    "    df_k['q_std_pred_list_v1'] = df_k.q_std_pred_list_v1.apply(lambda v: eval(v))\n",
    "\n",
    "    df_k['q_std_pred_list_2'] = df_k.apply(lambda row: get_sec_result(row['q_sim'], row['q_std_pred_list_v1']), axis=1)\n",
    "\n",
    "    df_k['q_std_pred_list_2_v1'] = df_k.q_std_pred_list_2.apply(lambda v: [k[0] for k in v])\n",
    "    df_k['q_std_pred_list_2_v2'] = df_k.q_std_pred_list_2.apply(lambda v: [k[1] for k in v])\n",
    "    df_k['q_std_pred_2'] = df_k.q_std_pred_list_2_v1.apply(lambda v: v[0])\n",
    "    df_k['prob_2'] = df_k.q_std_pred_list_2_v2.apply(lambda v: v[0])\n",
    "\n",
    "    df_k['r1'] = df_k.apply(lambda row: 1 if row['q_std'] in row['q_std_pred_list_2_v1'][0:1] else 0, axis=1)\n",
    "    df_k['r3'] = df_k.apply(lambda row: 1 if row['q_std'] in row['q_std_pred_list_2_v1'][0:3] else 0, axis=1)\n",
    "    df_k['r5'] = df_k.apply(lambda row: 1 if row['q_std'] in row['q_std_pred_list_2_v1'][0:5] else 0, axis=1)\n",
    "    df_k['r10'] = df_k.apply(lambda row: 1 if row['q_std'] in row['q_std_pred_list_2_v1'][0:10] else 0, axis=1)\n",
    "\n",
    "    ##扣除不包含的标准问\n",
    "    print('目标语料准确率：——>')\n",
    "    print(df_k.shape)\n",
    "    df_1 = df_k\n",
    "    print('第一阶段整体准确率', df_1.t1.sum() / df_1.shape[0], df_1.t3.sum() / df_1.shape[0], df_1.t5.sum() / df_1.shape[0],\n",
    "          df_1.t10.sum() / df_1.shape[0])\n",
    "    df_2 = df_k[df_k.t10 == 1]\n",
    "    print('第二阶段整体准确率', df_2.r1.sum() / df_2.shape[0], df_2.r3.sum() / df_2.shape[0], df_2.r5.sum() / df_2.shape[0],\n",
    "          df_2.r10.sum() / df_2.shape[0])\n",
    "    df_3 = df_k\n",
    "    print('整体准确率', df_3.r1.sum() / df_3.shape[0], df_3.r3.sum() / df_3.shape[0], df_3.r5.sum() / df_3.shape[0],\n",
    "          df_3.r10.sum() / df_3.shape[0])\n",
    "\n",
    "    ##扣除不包含的标准问\n",
    "    print('目标语料准确率[有效标问]：——>')\n",
    "    df_k_need = df_k[df_k.ifin == 1]\n",
    "    print(df_k_need.shape)\n",
    "    df_1 = df_k_need\n",
    "    print('第一阶段整体准确率', df_1.t1.sum() / df_1.shape[0], df_1.t3.sum() / df_1.shape[0], df_1.t5.sum() / df_1.shape[0],\n",
    "          df_1.t10.sum() / df_1.shape[0])\n",
    "    df_2 = df_k_need[df_k_need.t10 == 1]\n",
    "    print('第二阶段整体准确率', df_2.r1.sum() / df_2.shape[0], df_2.r3.sum() / df_2.shape[0], df_2.r5.sum() / df_2.shape[0],\n",
    "          df_2.r10.sum() / df_2.shape[0])\n",
    "    df_3 = df_k_need\n",
    "    print('整体准确率', df_3.r1.sum() / df_3.shape[0], df_3.r3.sum() / df_3.shape[0], df_3.r5.sum() / df_3.shape[0],\n",
    "          df_3.r10.sum() / df_3.shape[0])\n",
    "\n",
    "    print(outputpath)\n",
    "    df_k.to_csv(outputpath, index=None, sep=\"\\t\")\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 获得单例文本预测结果"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import logging\n",
    "import torch.nn.functional as F\n",
    "import datetime\n",
    "import sys\n",
    "import torch\n",
    "import config_train as config\n",
    "from task_sentence_embedding_FinanceFAQ_step1_1 import model1\n",
    "from task_sentence_embedding_FinanceFAQ_step2_1 import model2\n",
    "\n",
    "text = \"我想开户\"\n",
    "\n",
    "class get_sim_first():\n",
    "    def __init__(self, step1_model_dir, step1_data_dir, step1_q_std_vector_filename):\n",
    "        self.model_dir = step1_model_dir\n",
    "        self.data_dir = step1_data_dir\n",
    "        self.q_std_filename = config.q_std_file\n",
    "        self.q_std_vector_filename = step1_q_std_vector_filename\n",
    "        self.q_std_path = os.path.join(self.data_dir, self.q_std_filename)\n",
    "        ## set gpu\n",
    "\n",
    "        ## load std questions\n",
    "        with open(self.q_std_path, 'r', encoding=\"utf-8\") as f:\n",
    "            data = f.readlines()\n",
    "        self.q_std_list = [v.strip() for v in data]\n",
    "        ## load std questions' vectors\n",
    "        self.std_sentence_embeddings = np.load(os.path.join(self.data_dir, self.q_std_vector_filename))\n",
    "        ## load model\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        self.model = model1\n",
    "\n",
    "    def cos_sim(self, vector_a, vector_b):\n",
    "        vector_a = np.mat(vector_a)\n",
    "        vector_b = np.mat(vector_b)\n",
    "        num = float(vector_a * vector_b.T)\n",
    "        denom = np.linalg.norm(vector_a) * np.linalg.norm(vector_b)\n",
    "        cos = num / denom\n",
    "        sim = 0.5 + 0.5 * cos\n",
    "        return sim\n",
    "\n",
    "    def cos_sim4matrix(self, arr, brr):\n",
    "        return 0.5 + 0.5 * (arr.dot(brr.T) / (np.sqrt(np.sum(arr * arr)) * np.sqrt(np.sum(brr * brr, axis=1))))\n",
    "\n",
    "    def cos_sim4matrix_2(self, arr, brr):\n",
    "        return (arr.dot(brr.T) / (np.sqrt(np.sum(arr * arr)) * np.sqrt(np.sum(brr * brr, axis=1))))\n",
    "\n",
    "    def get_topK(self, text, K=20):\n",
    "        text_embedding = self.model.encode([text])[0]\n",
    "        #         sims_with_std=np.array([self.cos_sim(vec,text_embedding) for vec in self.std_sentence_embeddings])\n",
    "        sims_with_std = np.array(self.cos_sim4matrix_2(text_embedding, self.std_sentence_embeddings))\n",
    "        sort_idx = np.argsort(-sims_with_std)[:K]\n",
    "        sims_q_sort = [self.q_std_list[idx] for idx in sort_idx]\n",
    "        sims_values = [sims_with_std[idx] for idx in sort_idx]\n",
    "        result = list(zip(sims_q_sort, sims_values))\n",
    "        return (result)\n",
    "\n",
    "\n",
    "class get_sim_second():\n",
    "    def __init__(self, step2_model_dir, step2_data_dir, step2_q_std_vector_filename):\n",
    "        self.model_dir = step2_model_dir\n",
    "        self.data_dir = step2_data_dir\n",
    "        self.q_std_filename = config.sec_q_std_file\n",
    "        self.q_std_vector_filename = step2_q_std_vector_filename\n",
    "        self.q_std_path = os.path.join(self.data_dir, self.q_std_filename)\n",
    "\n",
    "        ## set gpu\n",
    "\n",
    "        ## load std questions\n",
    "        with open(self.q_std_path, 'r', encoding=\"utf-8\") as f:\n",
    "            data = f.readlines()\n",
    "        self.q_std_list = [v.strip() for v in data]\n",
    "        ## load std questions' vectors\n",
    "        self.std_sentence_embeddings = np.load(os.path.join(self.data_dir, self.q_std_vector_filename))\n",
    "        self.corpus_sentence_embeddings_dict_sec = dict(list(zip(self.q_std_list, self.std_sentence_embeddings)))\n",
    "        ## load model\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        self.model = model2\n",
    "\n",
    "    def cos_sim(self, vector_a, vector_b):\n",
    "        vector_a = np.mat(vector_a)\n",
    "        vector_b = np.mat(vector_b)\n",
    "        num = float(vector_a * vector_b.T)\n",
    "        denom = np.linalg.norm(vector_a) * np.linalg.norm(vector_b)\n",
    "        cos = num / denom\n",
    "        sim = 0.5 + 0.5 * cos\n",
    "        return sim\n",
    "\n",
    "    def cos_sim4matrix(self, arr, brr):\n",
    "        return 0.5 + 0.5 * (arr.dot(brr.T) / (np.sqrt(np.sum(arr * arr)) * np.sqrt(np.sum(brr * brr, axis=1))))\n",
    "\n",
    "    def cos_sim4matrix_2(self, arr, brr):\n",
    "        return (arr.dot(brr.T) / (np.sqrt(np.sum(arr * arr)) * np.sqrt(np.sum(brr * brr, axis=1))))\n",
    "\n",
    "    def get_topK(self, text, K=20):\n",
    "        text_embedding = self.model.encode([text])[0]\n",
    "        #         sims_with_std=np.array([self.cos_sim(vec,text_embedding) for vec in self.std_sentence_embeddings])\n",
    "        sims_with_std = np.array(self.cos_sim4matrix_2(text_embedding, self.std_sentence_embeddings))\n",
    "        sort_idx = np.argsort(-sims_with_std)[:K]\n",
    "        sims_q_sort = [self.q_std_list[idx] for idx in sort_idx]\n",
    "        sims_values = [sims_with_std[idx] for idx in sort_idx]\n",
    "        result = list(zip(sims_q_sort, sims_values))\n",
    "        return (result)\n",
    "\n",
    "\n",
    "set_model_gpu(setgpu=True)\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "\n",
    "\n",
    "def pytorch_cos_sim(a: Tensor, b: Tensor):\n",
    "    if not isinstance(a, torch.Tensor):\n",
    "        a = torch.tensor(a)\n",
    "\n",
    "    if not isinstance(b, torch.Tensor):\n",
    "        b = torch.tensor(b)\n",
    "\n",
    "    if len(a.shape) == 1:\n",
    "        a = a.unsqueeze(0)\n",
    "\n",
    "    if len(b.shape) == 1:\n",
    "        b = b.unsqueeze(0)\n",
    "\n",
    "    a_norm = a / a.norm(dim=1)[:, None]\n",
    "    b_norm = b / b.norm(dim=1)[:, None]\n",
    "    return torch.mm(a_norm, b_norm.transpose(0, 1))\n",
    "\n",
    "\n",
    "get_sim_step1 = get_sim_first(config.fst_model_dir, config.fst_data_dir, config.fst_q_std_vectors_file)\n",
    "get_sim_step2 = get_sim_second(config.sec_model_dir, config.sec_data_dir, config.sec_q_std_vectors_file)\n",
    "\n",
    "print('标准问数量', len(get_sim_step1.q_std_list), len(get_sim_step2.q_std_list))\n",
    "\n",
    "\n",
    "def get_sec_result(text, std_texts):\n",
    "    a_text_embeddings = x_texts_embeddings_dict_2[text]\n",
    "    b_text_embeddings = np.array([get_sim_step2.corpus_sentence_embeddings_dict_sec[v] for v in std_texts])\n",
    "    #     print(a_text_embeddings.shape,b_text_embeddings.shape)\n",
    "    sims_with_std = cos_sim4matrix_2(a_text_embeddings, b_text_embeddings).reshape(-1)\n",
    "    sort_idx = np.argsort(-sims_with_std).tolist()\n",
    "    intents_sort = [std_texts[idx] for idx in sort_idx]\n",
    "    sims_values = [sims_with_std[idx] for idx in sort_idx]\n",
    "    result = list(zip(intents_sort, sims_values))\n",
    "    return (result)\n",
    "\n",
    "\n",
    "# get_sec_result(text,std_texts)\n",
    "\n",
    "\n",
    "# 第一阶段\n",
    "time1 = datetime.datetime.now();\n",
    "print(time1)\n",
    "print('************', text)\n",
    "result_first = get_sim_step1.get_topK(text=text, K=10)\n",
    "print('第一阶段\\n', result_first[0:20])\n",
    "first_intents = [v[0] for v in result_first]\n",
    "a_texts_embeddings_2 = np.array(get_sim_step2.model.encode([text]))\n",
    "b_texts_embeddings_2 = np.array([get_sim_step2.corpus_sentence_embeddings_dict_sec[v] for v in first_intents])\n",
    "sims_with_std = get_sim_step2.cos_sim4matrix_2(a_texts_embeddings_2, b_texts_embeddings_2).reshape(-1)\n",
    "sort_idx = np.argsort(-sims_with_std).tolist()\n",
    "intents_sort = [first_intents[idx] for idx in sort_idx]\n",
    "sims_values = [sims_with_std[idx] for idx in sort_idx]\n",
    "result_second = list(zip(intents_sort, sims_values))\n",
    "\n",
    "time2 = datetime.datetime.now();\n",
    "print(time2)\n",
    "time_diff = time2 - time1;\n",
    "print('cost time:', time_diff.seconds)\n",
    "\n",
    "print('*************************')\n",
    "print('第二阶段\\n', result_second[0:20])\n",
    "\n",
    "# # x='电脑版官方网站'\n",
    "# y='钠离子电池对行业的影响'\n",
    "# print(get_sim_step2.cos_sim4matrix_2(np.array(get_sim_step1.model.encode([text])),np.array(get_sim_step1.model.encode([y]))))\n",
    "# # print('x',np.array(get_sim_step2.model.encode([x]))\n",
    "# # print('y',np.array(get_sim_step2.model.encode([y]))\n",
    "# # print(get_sim_step2.cos_sim4matrix_2(np.array(get_sim_step2.model.encode([x])),np.array(get_sim_step2.model.encode([y]))))\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}